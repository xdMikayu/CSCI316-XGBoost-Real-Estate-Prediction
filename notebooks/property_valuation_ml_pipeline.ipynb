{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B647AfUYdfQX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_date, expr\n",
        "from pyspark.sql.functions import sum as pyspark_sum\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ic1JGmcyvJl-"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the folder you want to delete\n",
        "folder_path = '/content/cleaned_valuation_data.csv'\n",
        "\n",
        "# Check if the file exists before deleting\n",
        "if os.path.exists(folder_path):\n",
        "       shutil.rmtree(folder_path)  # Use shutil.rmtree to delete directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_bo-iSYstYi",
        "outputId": "bb95807a-9907-41b1-b631-93a06848eaad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------------+-------------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-------+--------------------+--------------------+-----------+--------------------+\n",
            "|procedure_id|procedure_name_ar|  procedure_name_en|procedure_year|procedure_number|instance_date|actual_worth|row_status_code|procedure_area|property_type_id|property_type_ar|property_type_en|property_sub_type_id|property_sub_type_ar|property_sub_type_en|area_id|        area_name_ar|        area_name_en|actual_area|property_total_value|\n",
            "+------------+-----------------+-------------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-------+--------------------+--------------------+-----------+--------------------+\n",
            "|          24|       ÿ™ŸÇŸäŸäŸÖ ÿπŸÇÿßÿ±|Property Evaluation|          2005|             254|   30-04-2005|   9750000.0|      COMPLETED|        696.77|               1|             ÿßÿ±ÿ∂|            Land|                  62|              ÿ™ÿ¨ÿßÿ±Ÿäÿ©|          Commercial|    239|             ÿßŸÑÿ®ÿ±ÿßÿ≠Ÿá|           Al Baraha|     696.77|           9750000.0|\n",
            "|          24|       ÿ™ŸÇŸäŸäŸÖ ÿπŸÇÿßÿ±|Property Evaluation|          2009|             261|   16-03-2009|   3.98835E7|      COMPLETED|       2470.20|               1|             ÿßÿ±ÿ∂|            Land|                  62|              ÿ™ÿ¨ÿßÿ±Ÿäÿ©|          Commercial|    368|      ÿßŸÑÿ®ÿ±ÿ¥ÿßÿ° ÿßŸÑÿßŸàŸÑŸâ|     Al Barsha First|    2470.20|           3.98835E7|\n",
            "|          24|       ÿ™ŸÇŸäŸäŸÖ ÿπŸÇÿßÿ±|Property Evaluation|          2004|             268|   18-04-2004|   4000000.0|      COMPLETED|       4455.35|               1|             ÿßÿ±ÿ∂|            Land|                  11|   ŸÖÿÆÿßÿ≤ŸÜ ÿßŸà ŸÖÿ≥ÿ™ŸàÿØÿπÿßÿ™|           Warehouse|    319|ÿ±ÿßÿ≥ ÿßŸÑÿÆŸàÿ± ÿßŸÑÿµŸÜÿßÿπŸä...|Ras Al Khor Indus...|    4455.35|           4000000.0|\n",
            "|          24|       ÿ™ŸÇŸäŸäŸÖ ÿπŸÇÿßÿ±|Property Evaluation|          2006|             272|   22-03-2006|   3000000.0|      COMPLETED|       1393.55|               1|             ÿßÿ±ÿ∂|            Land|                  63|               ÿ≥ŸÉŸÜŸäÿ©|         Residential|    369|     ÿßŸÑÿ®ÿ±ÿ¥ÿßÿ° ÿßŸÑÿ´ÿßŸÑÿ´Ÿá|     Al Barsha Third|    1393.55|           3000000.0|\n",
            "|          24|       ÿ™ŸÇŸäŸäŸÖ ÿπŸÇÿßÿ±|Property Evaluation|          2005|             275|   08-05-2005|    2.6208E7|      COMPLETED|       4869.60|               1|             ÿßÿ±ÿ∂|            Land|                  65|              ÿµŸÜÿßÿπŸäÿ©|          Industrial|    378|             ÿßŸÑŸÇÿ±ŸáŸàÿØ|          Al Garhoud|    4869.60|            2.6208E7|\n",
            "+------------+-----------------+-------------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-------+--------------------+--------------------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- procedure_id: integer (nullable = true)\n",
            " |-- procedure_name_ar: string (nullable = true)\n",
            " |-- procedure_name_en: string (nullable = true)\n",
            " |-- procedure_year: integer (nullable = true)\n",
            " |-- procedure_number: integer (nullable = true)\n",
            " |-- instance_date: string (nullable = true)\n",
            " |-- actual_worth: double (nullable = true)\n",
            " |-- row_status_code: string (nullable = true)\n",
            " |-- procedure_area: string (nullable = true)\n",
            " |-- property_type_id: integer (nullable = true)\n",
            " |-- property_type_ar: string (nullable = true)\n",
            " |-- property_type_en: string (nullable = true)\n",
            " |-- property_sub_type_id: string (nullable = true)\n",
            " |-- property_sub_type_ar: string (nullable = true)\n",
            " |-- property_sub_type_en: string (nullable = true)\n",
            " |-- area_id: string (nullable = true)\n",
            " |-- area_name_ar: string (nullable = true)\n",
            " |-- area_name_en: string (nullable = true)\n",
            " |-- actual_area: string (nullable = true)\n",
            " |-- property_total_value: double (nullable = true)\n",
            "\n",
            "+------------+-----------------+-----------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-------+------------+------------+-----------+--------------------+\n",
            "|procedure_id|procedure_name_ar|procedure_name_en|procedure_year|procedure_number|instance_date|actual_worth|row_status_code|procedure_area|property_type_id|property_type_ar|property_type_en|property_sub_type_id|property_sub_type_ar|property_sub_type_en|area_id|area_name_ar|area_name_en|actual_area|property_total_value|\n",
            "+------------+-----------------+-----------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-------+------------+------------+-----------+--------------------+\n",
            "|           0|                0|                0|             0|               0|            0|           0|              0|             0|               0|               0|               0|                   0|                4934|                4934|      0|          60|          60|          0|                   0|\n",
            "+------------+-----------------+-----------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-------+------------+------------+-----------+--------------------+\n",
            "\n",
            "Dataframe with Arabic columns dropped\n",
            "+------------+-------------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+--------------------+--------------------+-------+--------------------+-----------+--------------------+\n",
            "|procedure_id|  procedure_name_en|procedure_year|procedure_number|instance_date|actual_worth|row_status_code|procedure_area|property_type_id|property_type_en|property_sub_type_id|property_sub_type_en|area_id|        area_name_en|actual_area|property_total_value|\n",
            "+------------+-------------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+--------------------+--------------------+-------+--------------------+-----------+--------------------+\n",
            "|          24|Property Evaluation|          2005|             254|   30-04-2005|   9750000.0|      COMPLETED|        696.77|               1|            Land|                  62|          Commercial|    239|           Al Baraha|     696.77|           9750000.0|\n",
            "|          24|Property Evaluation|          2009|             261|   16-03-2009|   3.98835E7|      COMPLETED|       2470.20|               1|            Land|                  62|          Commercial|    368|     Al Barsha First|    2470.20|           3.98835E7|\n",
            "|          24|Property Evaluation|          2004|             268|   18-04-2004|   4000000.0|      COMPLETED|       4455.35|               1|            Land|                  11|           Warehouse|    319|Ras Al Khor Indus...|    4455.35|           4000000.0|\n",
            "|          24|Property Evaluation|          2006|             272|   22-03-2006|   3000000.0|      COMPLETED|       1393.55|               1|            Land|                  63|         Residential|    369|     Al Barsha Third|    1393.55|           3000000.0|\n",
            "|          24|Property Evaluation|          2005|             275|   08-05-2005|    2.6208E7|      COMPLETED|       4869.60|               1|            Land|                  65|          Industrial|    378|          Al Garhoud|    4869.60|            2.6208E7|\n",
            "+------------+-------------------+--------------+----------------+-------------+------------+---------------+--------------+----------------+----------------+--------------------+--------------------+-------+--------------------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# pre processing step using Py Spark\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Data Preprocessing with PySpark\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 1: Load the CSV File\n",
        "df = spark.read.csv(\"Valuation.csv\", header=True, inferSchema=True)\n",
        "df.show(5)\n",
        "df.printSchema()\n",
        "\n",
        "#Find and remove the uncessary arabic columns\n",
        "# Identify Arabic columns (those ending with '_ar')\n",
        "arabic_columns = [col_name for col_name in df.columns if col_name.endswith(\"_ar\")]\n",
        "\n",
        "# Drop Arabic columns\n",
        "df_no_ar = df.drop(*arabic_columns)\n",
        "\n",
        "# Step 2: Check for Missing Values\n",
        "df.select([pyspark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()\n",
        "\n",
        "# Step 3: Remove Rows with Missing Values in 'actual_worth'\n",
        "df_clean = df_no_ar.filter(df_no_ar.actual_worth.isNotNull())\n",
        "\n",
        "#print the dataframe showing no arabic columns\n",
        "print(\"Dataframe with Arabic columns dropped\")\n",
        "df_clean.show(5)\n",
        "# Step 4: Convert Columns to Correct Data Types\n",
        "df_clean = df_clean.withColumn(\"instance_date\", to_date(col(\"instance_date\"), \"dd-MM-yyyy\")) \\\n",
        "                   .withColumn(\"procedure_area\", col(\"procedure_area\").cast(\"double\")) \\\n",
        "                   .withColumn(\"actual_area\", col(\"actual_area\").cast(\"double\")) \\\n",
        "                   .withColumn(\"property_sub_type_id\", col(\"property_sub_type_id\").cast(\"int\")) \\\n",
        "                   .withColumn(\"area_id\", col(\"area_id\").cast(\"int\"))\n",
        "\n",
        "# Step 5: Outlier Detection and Removal using IQR Method\n",
        "q1, q3 = df_clean.approxQuantile(\"actual_worth\", [0.25, 0.75], 0.01)\n",
        "iqr = q3 - q1\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "df_clean = df_clean.filter((col(\"actual_worth\") >= lower_bound) & (col(\"actual_worth\") <= upper_bound))\n",
        "\n",
        "# Step 6: Fill Missing Values\n",
        "# Fill missing 'procedure_area' with its median\n",
        "median_value = df_clean.approxQuantile(\"procedure_area\", [0.5], 0.01)[0]\n",
        "df_clean = df_clean.fillna({\"procedure_area\": median_value})\n",
        "\n",
        "# Fill missing 'instance_date' with the most common date\n",
        "most_common_date = df_clean.groupBy(\"instance_date\").count().orderBy(\"count\", ascending=False).first()[0]\n",
        "df_clean = df_clean.withColumn(\"instance_date\", expr(f\"coalesce(instance_date, '{most_common_date}')\"))\n",
        "\n",
        "# Step 7: Replace Unknowns with Most Common Sub-Type\n",
        "# Find the most common value in 'property_sub_type_en'\n",
        "mode_value = df_clean.groupBy(\"property_sub_type_en\").count().orderBy(\"count\", ascending=False).first()[0]\n",
        "\n",
        "df_clean = df_clean.withColumn(\"property_sub_type_en\", expr(f\"coalesce(nullif(property_sub_type_en, 'Unknown'), '{mode_value}')\"))\n",
        "\n",
        "# Step 8: Save the Cleaned Data to a New CSV File\n",
        "df_clean.write.csv(\"cleaned_valuation_data.csv\", header=True)\n",
        "\n",
        "# End Spark session\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9XRqiJgdm_G"
      },
      "outputs": [],
      "source": [
        "# --- Feature Engineering ---\n",
        "file_path = \"/content/cleaned_valuation_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df = df.drop(columns=[\"procedure_id\", \"procedure_name_en\", \"procedure_number\", \"property_type_id\",\"instance_date\"])\n",
        "categorical_cols = [\"property_type_en\", \"property_sub_type_en\", \"area_name_en\"]\n",
        "numerical_cols = [\"actual_worth\", \"actual_area\", \"property_total_value\"]\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = [\"row_status_code\", \"property_type_en\", \"area_name_en\"]\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "if all(col in df.columns for col in [\"property_type_en\", \"property_sub_type_en\", \"area_name_en\"]):\n",
        "    df.fillna({\"property_type_en\": \"Unknown\", \"property_sub_type_en\": \"Unknown\", \"area_name_en\": \"Unknown\"}, inplace=True)\n",
        "    df[[\"property_type_en\", \"property_sub_type_en\", \"area_name_en\"]] = df[[\"property_type_en\", \"property_sub_type_en\", \"area_name_en\"]].astype(str)\n",
        "df = pd.get_dummies(df, columns=[\"property_type_en\", \"property_sub_type_en\", \"area_name_en\"], drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "DReQcmyMHH0y",
        "outputId": "8b7a852b-a813-4694-db9f-2f5cf85c9c92"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-24466147-a33b-4e11-b698-248fa25c66a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>procedure_year</th>\n",
              "      <th>actual_worth</th>\n",
              "      <th>row_status_code</th>\n",
              "      <th>procedure_area</th>\n",
              "      <th>property_sub_type_id</th>\n",
              "      <th>area_id</th>\n",
              "      <th>actual_area</th>\n",
              "      <th>property_total_value</th>\n",
              "      <th>property_type_en_1</th>\n",
              "      <th>property_type_en_2</th>\n",
              "      <th>...</th>\n",
              "      <th>area_name_en_90</th>\n",
              "      <th>area_name_en_91</th>\n",
              "      <th>area_name_en_92</th>\n",
              "      <th>area_name_en_93</th>\n",
              "      <th>area_name_en_94</th>\n",
              "      <th>area_name_en_95</th>\n",
              "      <th>area_name_en_96</th>\n",
              "      <th>area_name_en_97</th>\n",
              "      <th>area_name_en_98</th>\n",
              "      <th>area_name_en_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2005</td>\n",
              "      <td>9750000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>696.77</td>\n",
              "      <td>62</td>\n",
              "      <td>239</td>\n",
              "      <td>696.77</td>\n",
              "      <td>9750000.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009</td>\n",
              "      <td>39883500.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2470.20</td>\n",
              "      <td>62</td>\n",
              "      <td>368</td>\n",
              "      <td>2470.20</td>\n",
              "      <td>39883500.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004</td>\n",
              "      <td>4000000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4455.35</td>\n",
              "      <td>11</td>\n",
              "      <td>319</td>\n",
              "      <td>4455.35</td>\n",
              "      <td>4000000.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006</td>\n",
              "      <td>3000000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1393.55</td>\n",
              "      <td>63</td>\n",
              "      <td>369</td>\n",
              "      <td>1393.55</td>\n",
              "      <td>3000000.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005</td>\n",
              "      <td>26208000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4869.60</td>\n",
              "      <td>65</td>\n",
              "      <td>378</td>\n",
              "      <td>4869.60</td>\n",
              "      <td>26208000.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 280 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24466147-a33b-4e11-b698-248fa25c66a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24466147-a33b-4e11-b698-248fa25c66a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24466147-a33b-4e11-b698-248fa25c66a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f84ef09b-52c2-4ec2-81ba-5a1b7e590a33\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f84ef09b-52c2-4ec2-81ba-5a1b7e590a33')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f84ef09b-52c2-4ec2-81ba-5a1b7e590a33 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   procedure_year  actual_worth  row_status_code  procedure_area  \\\n",
              "0            2005     9750000.0                1          696.77   \n",
              "1            2009    39883500.0                1         2470.20   \n",
              "2            2004     4000000.0                1         4455.35   \n",
              "3            2006     3000000.0                1         1393.55   \n",
              "4            2005    26208000.0                1         4869.60   \n",
              "\n",
              "   property_sub_type_id  area_id  actual_area  property_total_value  \\\n",
              "0                    62      239       696.77             9750000.0   \n",
              "1                    62      368      2470.20            39883500.0   \n",
              "2                    11      319      4455.35             4000000.0   \n",
              "3                    63      369      1393.55             3000000.0   \n",
              "4                    65      378      4869.60            26208000.0   \n",
              "\n",
              "   property_type_en_1  property_type_en_2  ...  area_name_en_90  \\\n",
              "0                True               False  ...            False   \n",
              "1                True               False  ...            False   \n",
              "2                True               False  ...            False   \n",
              "3                True               False  ...            False   \n",
              "4                True               False  ...            False   \n",
              "\n",
              "   area_name_en_91  area_name_en_92  area_name_en_93  area_name_en_94  \\\n",
              "0            False            False            False            False   \n",
              "1            False            False            False            False   \n",
              "2            False            False            False            False   \n",
              "3            False            False            False            False   \n",
              "4            False            False            False            False   \n",
              "\n",
              "   area_name_en_95  area_name_en_96  area_name_en_97  area_name_en_98  \\\n",
              "0            False            False            False            False   \n",
              "1            False            False            False            False   \n",
              "2            False            False            False            False   \n",
              "3            False            False            False            False   \n",
              "4            False            False            False            False   \n",
              "\n",
              "   area_name_en_99  \n",
              "0            False  \n",
              "1            False  \n",
              "2            False  \n",
              "3            False  \n",
              "4            False  \n",
              "\n",
              "[5 rows x 280 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iUlDVGwG_Ff",
        "outputId": "649443c6-acf7-48d7-ee8b-c3cdad4fdc8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70740, 280)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQr3I0pSHGse",
        "outputId": "c46a7c2d-9328-4315-8f5e-f331b14b0cfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average property_total_value: 8766339.30091264\n"
          ]
        }
      ],
      "source": [
        "\n",
        "average_property_value = df['property_total_value'].mean()\n",
        "print(f\"Average property_total_value: {average_property_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npY_1TIsij3k",
        "outputId": "90785487-1611-44af-ac66-365022430cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   actual_worth  actual_area  property_total_value\n",
            "0      0.095771    -0.118303              0.091028\n",
            "1      2.958169     0.035429              2.879571\n",
            "2     -0.450424     0.207514             -0.441075\n",
            "3     -0.545415    -0.057902             -0.533615\n",
            "4      1.659126     0.243423              1.614045\n"
          ]
        }
      ],
      "source": [
        "#scaling\n",
        "\n",
        "numerical_cols = [\"actual_worth\", \"actual_area\", \"property_total_value\"]\n",
        "scaler = StandardScaler()\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# View scaled data\n",
        "print(df[numerical_cols].head())  # View first 5 rows\n",
        "# Get descriptive statistics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wre1G-gVdpen"
      },
      "outputs": [],
      "source": [
        "# --- Data Splitting --- # 80% train, 20% test\n",
        "X = df.drop(columns=['actual_worth'])\n",
        "y = df['actual_worth']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_9iuVThdwmb",
        "outputId": "345db718-6095-4d94-b593-4d8007ff212a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train data types:\n",
            " procedure_year            int64\n",
            "row_status_code           int64\n",
            "procedure_area          float64\n",
            "property_sub_type_id      int64\n",
            "area_id                   int64\n",
            "                         ...   \n",
            "area_name_en_95            bool\n",
            "area_name_en_96            bool\n",
            "area_name_en_97            bool\n",
            "area_name_en_98            bool\n",
            "area_name_en_99            bool\n",
            "Length: 279, dtype: object\n",
            "\n",
            "X_train head:\n",
            "        procedure_year  row_status_code  procedure_area  property_sub_type_id  \\\n",
            "32520            2017                1         1025.25                    63   \n",
            "51652            2021                1          174.77                    42   \n",
            "16394            2014                1           45.00                    60   \n",
            "20727            2016                1           61.97                    60   \n",
            "60960            2023                1          334.45                    63   \n",
            "\n",
            "       area_id  actual_area  property_total_value  property_type_en_1  \\\n",
            "32520      266    -0.089829              0.516376                True   \n",
            "51652      526    -0.163554             -0.582733               False   \n",
            "16394      343    -0.174803             -0.770892               False   \n",
            "20727      330    -0.173332             -0.740186               False   \n",
            "60960      300    -0.149712             -0.690932                True   \n",
            "\n",
            "       property_type_en_2  property_sub_type_en_Airport  ...  area_name_en_90  \\\n",
            "32520               False                         False  ...            False   \n",
            "51652                True                         False  ...            False   \n",
            "16394                True                         False  ...            False   \n",
            "20727                True                         False  ...            False   \n",
            "60960               False                         False  ...            False   \n",
            "\n",
            "       area_name_en_91  area_name_en_92  area_name_en_93  area_name_en_94  \\\n",
            "32520            False            False            False            False   \n",
            "51652            False            False            False            False   \n",
            "16394            False            False            False            False   \n",
            "20727            False            False            False            False   \n",
            "60960            False            False            False            False   \n",
            "\n",
            "       area_name_en_95  area_name_en_96  area_name_en_97  area_name_en_98  \\\n",
            "32520            False            False            False            False   \n",
            "51652            False            False            False            False   \n",
            "16394            False             True            False            False   \n",
            "20727            False            False            False            False   \n",
            "60960            False            False            False            False   \n",
            "\n",
            "       area_name_en_99  \n",
            "32520            False  \n",
            "51652            False  \n",
            "16394            False  \n",
            "20727            False  \n",
            "60960            False  \n",
            "\n",
            "[5 rows x 279 columns]\n"
          ]
        }
      ],
      "source": [
        "# --- Preprocessing Validation ---\n",
        "print(\"X_train data types:\\n\", X_train.dtypes)  # Check data types after preprocessing\n",
        "print(\"\\nX_train head:\\n\", X_train.head())  # Check first few rows of train set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztGlJfnu-tJt"
      },
      "source": [
        "# Boosting model explanation\n",
        "\n",
        "## Why is boosting used\n",
        "\n",
        "Boosting is a an ensemble learing technique where multiple weak learners are combined to create a stronger, more accurate model. It is typically performed during the training phase of the machine learning model\n",
        "\n",
        "Boosting primarily aims to improve the accuracy and performance of a machine learning model by reducing the bias, improving generalization (by creating a model that is less prone to overfitting) and handling complex relationships by iteratively refining the model's predictions\n",
        "\n",
        "\n",
        "## Code explanation\n",
        "\n",
        "### Model\n",
        "The model is designed to mimic the behavior of XGBoost Regression from scratch without the use of the predefined library. The class uses a collection of weak learners to create a strong predictive model\n",
        "\n",
        "### Initialization\n",
        "\n",
        "```\n",
        "def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_split=10):\n",
        "    self.n_estimators = n_estimators\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.trees = []\n",
        "    self.base_pred = 0\n",
        "```\n",
        "\n",
        "- n_estimators: The number of decision trees to be used in the model\n",
        "- learning_rate: controls the step size during model updates, smaller values make the model learn more slowly but can improve generalization\n",
        "- max_depth: The maximum depth of each decision tree. This parameter limits the complexity of individual trees.\n",
        "- min_samples_split: The minimum number of samples required to split an internal node of a tree.\n",
        "trees: A list to store the trained decision trees.\n",
        "- base_pred: The initial prediction value, set to the average of the target variable.\n",
        "\n",
        "### Gradient calculation\n",
        "```\n",
        "def mean_squared_error_grad(self, y_true, y_pred):\n",
        "    \"\"\"Gradient of MSE Loss: ‚àÇL/‚àÇy_pred = 2 * (y_pred - y_true)\"\"\"\n",
        "    return 2 * (y_pred - y_true)\n",
        "```\n",
        "\n",
        "This function calculates the gradient of the Mean Squared Error (MSE) loss function. The gradient is used to guide the model updates during training.\n",
        "\n",
        "### Model training\n",
        "Define a function for training the defined regressor model from scratch\n",
        "\n",
        "```\n",
        "def fit(self, X, y):\n",
        "    \"\"\"Train the XGBoost regressor from scratch\"\"\"\n",
        "    # Initialize prediction with the mean of target variable\n",
        "    self.base_pred = np.mean(y)\n",
        "    y_pred = np.full(y.shape, self.base_pred)\n",
        "\n",
        "```\n",
        "Initializes the prediction with the average of the target variable.\n",
        "\n",
        "```\n",
        "    for _ in range(self.n_estimators):\n",
        "        # Compute negative gradients (residuals = errors made by the previous trees in predicting the target values)\n",
        "        residuals = -self.mean_squared_error_grad(y, y_pred)\n",
        "\n",
        "        # Fit weak learner (decision tree) to residuals\n",
        "        tree = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
        "        tree.fit(X, residuals)\n",
        "\n",
        "        # Get tree predictions and update overall prediction\n",
        "        update = tree.predict(X)\n",
        "        y_pred += self.learning_rate * update\n",
        "\n",
        "        # Store trained tree\n",
        "        self.trees.append(tree)\n",
        "```\n",
        "- Iterates through the specified number of estimators (n_estimators).\n",
        "  - Calculates the residuals (negative gradients) based on the current prediction and actual target values.\n",
        "  - Trains a decision tree on the residuals to capture the patterns in the errors.\n",
        "  - Updates the overall prediction by adding the weighted prediction of the current tree.\n",
        "  - Stores the trained tree in the trees list\n",
        "\n",
        "### Prediction\n",
        "\n",
        "```\n",
        "def predict(self, X):\n",
        "    \"\"\"Make predictions using the trained model\"\"\"\n",
        "    y_pred = np.full(X.shape[0], self.base_pred)  # Start with base prediction\n",
        "    for tree in self.trees:\n",
        "        y_pred += self.learning_rate * tree.predict(X)  # Add weak learner's contribution\n",
        "    return y_pred\n",
        "```\n",
        "- Initializes the prediction with the base prediction.\n",
        "- Iterates through the trained trees and adds their weighted predictions to the overall prediction.\n",
        "- Returns the final prediction.\n",
        "\n",
        "## Algorithm Explanation\n",
        "XGBoost Algorithm\n",
        "\n",
        "1.  Initialize the Model\n",
        "The first prediction is the mean of the target variable (for regression) or log-odds (for classification).\n",
        "Example: If predicting property_total_value, the first prediction is\n",
        "\n",
        "  ùë¶\n",
        "^\n",
        "=\n",
        "mean\n",
        "(\n",
        "ùë¶\n",
        ")\n",
        "\n",
        "\n",
        "2.  Compute Residuals (Negative Gradients)\n",
        "For each sample, compute the residuals (errors) from the previous prediction.\n",
        "\n",
        "  Residual\n",
        "=\n",
        "ùë¶\n",
        "true\n",
        "‚àí\n",
        "ùë¶\n",
        "^\n",
        "\n",
        "\n",
        "  These residuals act as the new target for the next tree.\n",
        "\n",
        "3.  Fit a Decision Tree on Residuals\n",
        "A small tree (weak learner) is trained to predict these residuals.\n",
        "The tree learns which features contribute most to reducing errors.\n",
        "\n",
        "4.  Compute the Output Value for Each Leaf\n",
        "Unlike traditional boosting, XGBoost doesn't directly predict residuals.\n",
        "Instead, it computes an optimal output value for each leaf of the tree, based on the residuals and second-order gradients (Hessian).\n",
        "\n",
        "  ùë§\n",
        "ùëó\n",
        "=\n",
        "‚àí\n",
        "(‚àë\n",
        "Gradients /\n",
        "‚àë\n",
        "Hessians + ùúÜ)\n",
        "\n",
        "\n",
        "  - Gradients: First derivative of the loss function (indicates direction of error reduction).\n",
        "  - Hessians: Second derivative (indicates confidence in the gradient).\n",
        "\n",
        "  - Œª: Regularization term to prevent overfitting.\n",
        "\n",
        "5.  Update Predictions\n",
        "Update the model by adding the new tree‚Äôs weighted predictions:\n",
        "ùë¶\n",
        "^\n",
        "=\n",
        "ùë¶\n",
        "^\n",
        "(previous) + ùúÇ ‚ãÖ ùë§ ùëó\n",
        "\n",
        "\n",
        "\n",
        "- Œ∑: (learning rate) controls how much each tree contributes.\n",
        "- Small Œ∑ values require more trees but improve generalization.\n",
        "6.  Repeat Steps 2‚Äì5 for Multiple Trees\n",
        "Keep training new trees on updated residuals.\n",
        "Stop when:\n",
        "The max number of trees is reached.\n",
        "The improvement in loss is below a threshold.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbyqysHyd9D2"
      },
      "outputs": [],
      "source": [
        "# --- XGBoost from Scratch Implementation ---\n",
        "class XGBoostRegressorScratch:\n",
        "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_split=10):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.trees = []  # List to store weak decision tree models\n",
        "        self.base_pred = 0  # Initial prediction value (for boosting)\n",
        "\n",
        "    def mean_squared_error_grad(self, y_true, y_pred):\n",
        "        \"\"\"Gradient of MSE Loss: ‚àÇL/‚àÇy_pred = 2 * (y_pred - y_true)\"\"\"\n",
        "        return 2 * (y_pred - y_true)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train the XGBoost regressor from scratch\"\"\"\n",
        "        # Initialize prediction with the mean of target variable\n",
        "        self.base_pred = np.mean(y)\n",
        "        y_pred = np.full(y.shape, self.base_pred)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            # Compute negative gradients (residuals)\n",
        "            residuals = -self.mean_squared_error_grad(y, y_pred)\n",
        "\n",
        "            # Fit weak learner (decision tree) to residuals\n",
        "            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
        "            tree.fit(X, residuals)\n",
        "\n",
        "            # Get tree predictions and update overall prediction\n",
        "            update = tree.predict(X)\n",
        "            y_pred += self.learning_rate * update\n",
        "\n",
        "            # Store trained tree\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions using the trained model\"\"\"\n",
        "        y_pred = np.full(X.shape[0], self.base_pred)  # Start with base prediction\n",
        "        for tree in self.trees:\n",
        "            y_pred += self.learning_rate * tree.predict(X)  # Add weak learner's contribution\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EhIcb2ctxHO",
        "outputId": "ae6ce2b5-8e42-4f88-f7bb-537532ca276c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean RMSE (Cross-Validation): 0.06\n",
            "Standard Deviation of RMSE (Cross-Validation): 0.02\n",
            "Mean R-squared (Cross-Validation): 1.00\n",
            "Standard Deviation of R-squared (Cross-Validation): 0.00\n",
            "Mean MAE (Cross-Validation) Training: 0.01\n",
            "Standard Deviation of MAE (Cross-Validation)Training: 0.00\n",
            "Mean MedAE (Cross-Validation) Training: 0.01\n",
            "Standard Deviation of MedAE (Cross-Validation) Training: 0.00\n",
            "Mean Explained Variance (Cross-Validation) Training: 1.00\n",
            "Standard Deviation of Explained Variance (Cross-Validation)Training: 0.00\n"
          ]
        }
      ],
      "source": [
        "# --- Cross-Validation for boosting model  ---\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "rmse_scores = []\n",
        "r2_scores = []\n",
        "mae_scores = []\n",
        "medae_scores = []\n",
        "explained_variance_scores = []\n",
        "\n",
        "\n",
        "for train_index, test_index in kf.split(X_train):  # Cross-validation on training set\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    model = XGBoostRegressorScratch(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    y_pred_fold = model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate metrics for this fold\n",
        "    rmse_fold = np.sqrt(np.mean((y_pred_fold - y_val_fold) ** 2))\n",
        "    rmse_scores.append(rmse_fold)\n",
        "\n",
        "    r2_fold = r2_score(y_val_fold, y_pred_fold)\n",
        "    r2_scores.append(r2_fold)\n",
        "\n",
        "    mae_fold = mean_absolute_error(y_val_fold, y_pred_fold)\n",
        "    mae_scores.append(mae_fold)\n",
        "\n",
        "    medae_fold = median_absolute_error(y_val_fold, y_pred_fold)\n",
        "    medae_scores.append(medae_fold)\n",
        "\n",
        "    explained_variance_fold = explained_variance_score(y_val_fold, y_pred_fold)\n",
        "    explained_variance_scores.append(explained_variance_fold)\n",
        "\n",
        "\n",
        "# Print results for training set\n",
        "print(f\"Mean RMSE (Cross-Validation): {np.mean(rmse_scores):.2f}\")\n",
        "print(f\"Standard Deviation of RMSE (Cross-Validation): {np.std(rmse_scores):.2f}\")\n",
        "print(f\"Mean R-squared (Cross-Validation): {np.mean(r2_scores):.2f}\")\n",
        "print(f\"Standard Deviation of R-squared (Cross-Validation): {np.std(r2_scores):.2f}\")\n",
        "print(f\"Mean MAE (Cross-Validation) Training: {np.mean(mae_scores):.2f}\")\n",
        "print(f\"Standard Deviation of MAE (Cross-Validation)Training: {np.std(mae_scores):.2f}\")\n",
        "print(f\"Mean MedAE (Cross-Validation) Training: {np.mean(medae_scores):.2f}\")\n",
        "print(f\"Standard Deviation of MedAE (Cross-Validation) Training: {np.std(medae_scores):.2f}\")\n",
        "print(f\"Mean Explained Variance (Cross-Validation) Training: {np.mean(explained_variance_scores):.2f}\")\n",
        "print(f\"Standard Deviation of Explained Variance (Cross-Validation)Training: {np.std(explained_variance_scores):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La3ah7z8wgWm",
        "outputId": "f0f4a678-4d4b-4907-d9ed-a201bbb9a10d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE on Test Set: 0.05\n",
            "R-squared on Test Set: 1.00\n",
            "MAE on Test Set: 0.01\n",
            "Mean Explained Variance on Test Set: 1.00\n"
          ]
        }
      ],
      "source": [
        "# --- Final Evaluation on Test Set for XG boosting  ---\n",
        "model = XGBoostRegressorScratch(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "model.fit(X_train, y_train)  # Train on the entire training set\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_test = np.sqrt(np.mean((y_pred_test - y_test) ** 2))\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "# Calculate MAE\n",
        "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "# Calculate mean explained variance\n",
        "explained_variance_test = explained_variance_score(y_test, y_pred_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE on Test Set: {rmse_test:.2f}\")\n",
        "print(f\"R-squared on Test Set: {r2_test:.2f}\")\n",
        "print(f\"MAE on Test Set: {mae_test:.2f}\")\n",
        "print(f\"Mean Explained Variance on Test Set: {explained_variance_test:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DRs4oRcyawg"
      },
      "source": [
        "#**Bagging Ensemble Model Explanation**\n",
        "Bagging (Bootstrap Aggregating) is an ensemble learning technique that improves the accuracy and stability of machine learning models by combining multiple weak learners (typically decision trees) into a stronger model. The key idea behind bagging is:\n",
        "\n",
        "**Reducing Variance**: Each model is trained on a random subset of data, making the final prediction less sensitive to individual data variations.\n",
        "\n",
        "**Improving Generalization**: Averaging multiple predictions reduces overfitting and enhances robustness.\n",
        "\n",
        "**Handling Noise**: By training different models on different bootstrapped samples, bagging helps mitigate the impact of outliers and noisy data.\n",
        "\n",
        "Bagging is particularly useful for high-variance models such as decision trees, where individual trees may be sensitive to specific data points.\n",
        "\n",
        "# **Code Explanation**\n",
        "\n",
        "**Model**\n",
        "\n",
        "The model implements a Bagging Regressor from scratch, using multiple DecisionTreeRegressor models. It follows a standard ensemble learning approach by training multiple models on random subsets of data and averaging their predictions.\n",
        "\n",
        "**Initialization**\n",
        "```\n",
        "def __init__(self, base_estimator=DecisionTreeRegressor, n_estimators=10, max_samples=0.8):\n",
        "    self.base_estimator = base_estimator\n",
        "    self.n_estimators = n_estimators\n",
        "    self.max_samples = max_samples\n",
        "    self.models = []\n",
        "\n",
        "```\n",
        "base_estimator: Specifies the weak learner (Decision Tree Regressor in this case).\n",
        "\n",
        "n_estimators: Number of base models (trees) to train.\n",
        "\n",
        "max_samples: Proportion of training data used for each model (default: 80% of dataset).\n",
        "\n",
        "models: Stores the trained models.  \n",
        "\n",
        "```\n",
        "def fit(self, X, y):\n",
        "    np.random.seed(42)\n",
        "    n_samples = int(self.max_samples * len(X))\n",
        "    for _ in range(self.n_estimators):\n",
        "        sample_indices = np.random.choice(len(X), n_samples, replace=True)\n",
        "        X_sample, y_sample = X.iloc[sample_indices], y.iloc[sample_indices]\n",
        "        model = self.base_estimator()\n",
        "        model.fit(X_sample, y_sample)\n",
        "        self.models.append(model)\n",
        "```\n",
        "Creates n_estimators decision trees.\n",
        "\n",
        "Each tree is trained on a random subset of data (bootstrap sampling).\n",
        "\n",
        "Trees are stored in self.models.\n",
        "\n",
        "```\n",
        "def predict(self, X):\n",
        "    predictions = np.array([model.predict(X) for model in self.models])\n",
        "    return np.mean(predictions, axis=0)\n",
        "```\n",
        "\n",
        "Each model makes a prediction.\n",
        "\n",
        "The final prediction is the average of all model outputs, reducing variance.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQkkFJ0Ykrpe"
      },
      "outputs": [],
      "source": [
        "# Bagging Ensemble Model from Scratch\n",
        "class BaggingRegressorScratch:\n",
        "    def __init__(self, base_estimator=DecisionTreeRegressor, n_estimators=10, max_samples=0.8):\n",
        "        self.base_estimator = base_estimator\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_samples = max_samples\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        np.random.seed(42)\n",
        "        n_samples = int(self.max_samples * len(X))\n",
        "        for _ in range(self.n_estimators):\n",
        "            sample_indices = np.random.choice(len(X), n_samples, replace=True)\n",
        "            X_sample, y_sample = X.iloc[sample_indices], y.iloc[sample_indices]\n",
        "            model = self.base_estimator()\n",
        "            model.fit(X_sample, y_sample)\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.array([model.predict(X) for model in self.models])\n",
        "        return np.mean(predictions, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ycYwxNBlfsb",
        "outputId": "e28ac2bb-b84c-44d8-a5dc-c3fc403a9c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean RMSE (Cross-Validation) Training: 0.06\n",
            "Mean R-squared (Cross-Validation) Training: 1.00\n",
            "Mean MAE (Cross-Validation): Training 0.00\n"
          ]
        }
      ],
      "source": [
        "# Perform 10-Fold Cross-Validation on training set for Bagging model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "rmse_scores, r2_scores, mae_scores = [], [], []\n",
        "\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    model = BaggingRegressorScratch(n_estimators=10)\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "    y_pred_fold = model.predict(X_val_fold)\n",
        "\n",
        "    rmse_scores.append(np.sqrt(mean_squared_error(y_val_fold, y_pred_fold)))\n",
        "    r2_scores.append(r2_score(y_val_fold, y_pred_fold))\n",
        "    mae_scores.append(mean_absolute_error(y_val_fold, y_pred_fold))\n",
        "\n",
        "# Print Cross-Validation Results\n",
        "print(f\"Mean RMSE (Cross-Validation) Training: {np.mean(rmse_scores):.2f}\")\n",
        "print(f\"Mean R-squared (Cross-Validation) Training: {np.mean(r2_scores):.2f}\")\n",
        "print(f\"Mean MAE (Cross-Validation): Training {np.mean(mae_scores):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZZHrE13qFSW",
        "outputId": "59fa61e1-94b9-4cd6-d546-2efa07262d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bagging - RMSE on Test Set: 0.05\n",
            "Bagging - R-squared on Test Set: 1.00\n",
            "Bagging - MAE on Test Set: 0.00\n",
            "Bagging - Mean Explained Variance on Test Set: 1.00\n"
          ]
        }
      ],
      "source": [
        "# --- Final Evaluation on Test Set for BaggingRegressorScratch ---\n",
        "bagging_model = BaggingRegressorScratch(n_estimators=10)  # Initialize your Bagging model\n",
        "bagging_model.fit(X_train, y_train)  # Train on the entire training set\n",
        "y_pred_test_bagging = bagging_model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_test_bagging = np.sqrt(mean_squared_error(y_test, y_pred_test_bagging))\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_test_bagging = r2_score(y_test, y_pred_test_bagging)\n",
        "\n",
        "# Calculate MAE\n",
        "mae_test_bagging = mean_absolute_error(y_test, y_pred_test_bagging)\n",
        "\n",
        "# Calculate mean explained variance\n",
        "explained_variance_test_bagging = explained_variance_score(y_test, y_pred_test_bagging)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(f\"Bagging - RMSE on Test Set: {rmse_test_bagging:.2f}\")\n",
        "print(f\"Bagging - R-squared on Test Set: {r2_test_bagging:.2f}\")\n",
        "print(f\"Bagging - MAE on Test Set: {mae_test_bagging:.2f}\")\n",
        "print(f\"Bagging - Mean Explained Variance on Test Set: {explained_variance_test_bagging:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}